{
  "hash": "17412dd790e74619a36f28ae34a5f29c",
  "result": {
    "engine": "jupyter",
    "markdown": "# Principle Component Analysis\n\nSince the merge between the datasets created a lot of columns (over 2,000), it's necesary to reduce the dimensions of the dataset with PCA before running the k-means algorithm.\n\n## Import Statements\n\n::: {#52ac4cb3-1898-4cc4-8d67-bd05321a424b .cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {#923e0a7c-dfb8-412b-a374-1f35dd9b3b4f .cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv(\"bofedales-clean.csv\")\ndf = df.drop([\"Unnamed: 0\"], axis=1)\ndf.isna().sum().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nnp.int64(0)\n```\n:::\n:::\n\n\n::: {#f407bfa6-be61-474e-ac92-31bd23b05a6c .cell execution_count=3}\n``` {.python .cell-code}\ndf.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n(2534, 2289)\n```\n:::\n:::\n\n\n::: {#9f3c2c0e-b697-4799-822f-85bc537221f8 .cell execution_count=4}\n``` {.python .cell-code}\ndf.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Area_m2</th>\n      <th>AUC</th>\n      <th>pct_prot</th>\n      <th>elev_mean_</th>\n      <th>elev_std_m</th>\n      <th>n_wells</th>\n      <th>Ground Water Rights 1966-01-01</th>\n      <th>Ground Water Rights 1967-01-01</th>\n      <th>Ground Water Rights 1968-01-01</th>\n      <th>Ground Water Rights 1969-01-01</th>\n      <th>...</th>\n      <th>NDWI 2019-03</th>\n      <th>NDWI 2019-04</th>\n      <th>NDWI 2019-05</th>\n      <th>NDWI 2019-06</th>\n      <th>NDWI 2019-07</th>\n      <th>NDWI 2019-08</th>\n      <th>NDWI 2019-09</th>\n      <th>NDWI 2019-10</th>\n      <th>NDWI 2019-11</th>\n      <th>NDWI 2019-12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6300</td>\n      <td>86.769539</td>\n      <td>0.0</td>\n      <td>4162.714286</td>\n      <td>3.953815</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.031930</td>\n      <td>0.026136</td>\n      <td>0.022087</td>\n      <td>0.019181</td>\n      <td>0.023405</td>\n      <td>0.015355</td>\n      <td>-0.000504</td>\n      <td>0.004056</td>\n      <td>0.014678</td>\n      <td>0.010436</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5400</td>\n      <td>83.176353</td>\n      <td>0.0</td>\n      <td>4073.500000</td>\n      <td>12.406316</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.057992</td>\n      <td>-0.053230</td>\n      <td>-0.054671</td>\n      <td>-0.064990</td>\n      <td>-0.063351</td>\n      <td>-0.074670</td>\n      <td>-0.085071</td>\n      <td>-0.081491</td>\n      <td>-0.061333</td>\n      <td>-0.055450</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6300</td>\n      <td>103.719438</td>\n      <td>0.0</td>\n      <td>4278.571429</td>\n      <td>6.161102</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.065899</td>\n      <td>0.070822</td>\n      <td>0.070075</td>\n      <td>0.068015</td>\n      <td>0.068144</td>\n      <td>0.062340</td>\n      <td>0.047670</td>\n      <td>0.050570</td>\n      <td>0.056227</td>\n      <td>0.059294</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 2289 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Finding the Optimal Number of Principle Components\n\nFirst, check how many principle components account for 90% of the variance in the data\n\n::: {#0ddb4d30-c02a-4a87-bd82-a1ea0786fc10 .cell execution_count=5}\n``` {.python .cell-code}\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df)  \n```\n:::\n\n\n::: {#4f4b1efe-2f76-4282-ba64-108549edea76 .cell execution_count=6}\n``` {.python .cell-code}\nx_per_variance = 0.90\n\npca = PCA(n_components=x_per_variance, svd_solver=\"full\")\nX_pca = pca.fit_transform(X_scaled)\nprint(f\"Number of principal components chosen to explain {x_per_variance * 100}% variance: {pca.n_components_}\")\nprint(\"Explained variance ratio (per PC):\")\nprint(np.round(pca.explained_variance_ratio_, 4))\nprint(\"Cumulative explained variance:\", round(pca.explained_variance_ratio_.cumsum()[-1], 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of principal components chosen to explain 90.0% variance: 5\nExplained variance ratio (per PC):\n[0.7058 0.0929 0.0571 0.0397 0.0334]\nCumulative explained variance: 0.9289\n```\n:::\n:::\n\n\nFive PCs account for 90% of the variance, so the data can easily be greatly reduced in dimensionality.\n\nNext, graph variance versus PCs. The elbow in the graph has the optional number of PCs -- afterwards, there are diminishing returns.\n\n::: {#7143d529-9e4e-4abd-9308-28597007a085 .cell execution_count=7}\n``` {.python .cell-code}\nfeatures_for_pca = df.columns.tolist()\n\npca_full = PCA()\npca_full.fit(X_scaled)\n\ncum_var = np.cumsum(pca_full.explained_variance_ratio_)\n\n# 6) Plot the \"elbow\" (cumulative explained variance vs. number of components)\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, len(cum_var) + 1), cum_var, marker='o', linewidth=2)\nplt.axhline(y=0.90, color='r', linestyle='--', label='90% Threshold')\nplt.axhline(y=0.99, color='g', linestyle='--', label='99% Threshold')\nplt.xlabel(\"Number of Principal Components\")\nplt.ylabel(\"Cumulative Explained Variance\")\nplt.title(\"Elbow Plot: Cumulative Explained Variance by Number of PCs\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\nplt.xlim(1, 50)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](PCA_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\nSince the \"elbow\" of the curve occurs at around 7 or 6 PCs, this is the value that will be used in analyzing the data\n\n## Run PCA with 6 Components\n\n::: {#f37937e8-6ed1-43de-b963-e59bf2327f9a .cell execution_count=8}\n``` {.python .cell-code}\npca6 = PCA(n_components=6)\nX_ = pca6.fit_transform(X_scaled)\n```\n:::\n\n\nSave the dataset to be run in future notebooks:\n\n::: {#0091305e-735b-481b-aedd-7effdebcc635 .cell execution_count=9}\n``` {.python .cell-code}\nnp.save(\"scaled-df.npy\", X_)\n```\n:::\n\n\n\n",
    "supporting": [
      "PCA_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}